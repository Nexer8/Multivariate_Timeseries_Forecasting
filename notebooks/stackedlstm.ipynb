{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Assignment 2 | Image Classification, December 2021\n\n- [Artificial Neural Networks and Deep Learning 2021 - Homework 2](https://codalab.lisn.upsaclay.fr/competitions/621)\n\n## Three convolutioneers\n\n- *Aleksandra Krajnovic*\n- *Iva Milojkovic*\n- *Mariusz Wi≈õniewski*","metadata":{"id":"zHQSWf9b1M6e"}},{"cell_type":"markdown","source":"### Connect to Drive","metadata":{"id":"nmKMLFLdfdhL"}},{"cell_type":"code","source":"# from google.colab import drive\n# drive.mount('/gdrive')","metadata":{"id":"fIPnkn7fcGLp","outputId":"c9aeb927-f3f6-422c-c0f6-8012a8c92dfe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %cd /gdrive/My Drive/Colab Notebooks/ANN_Homework2","metadata":{"id":"hyPYQ85XffFB","outputId":"e7ccf606-9a9c-476e-950c-de1288e6e890"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Import libraries","metadata":{"id":"ap3o8JayfgEM"}},{"cell_type":"code","source":"import os\nimport random\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\n\nplt.rc('font', size=16)\nimport warnings\n\nwarnings.filterwarnings('ignore')\ntf.get_logger().setLevel('ERROR')\n\ntfk = tf.keras\ntfkl = tf.keras.layers\nprint(tf.__version__)","metadata":{"id":"CesUrUpUtKTp","outputId":"ee47c6af-3fa1-41e8-e016-dab630655282"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Set seed for reproducibility","metadata":{"id":"cfIcXow5tRUY"}},{"cell_type":"code","source":"# Random seed for reproducibility\nseed = 42\n\nrandom.seed(seed)\nos.environ['PYTHONHASHSEED'] = str(seed)\nnp.random.seed(seed)\ntf.random.set_seed(seed)\ntf.compat.v1.set_random_seed(seed)","metadata":{"id":"-LDmmEgOtKsO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Utility function to create folders and callbacks for training","metadata":{"id":"ytcTBpgA1M6r"}},{"cell_type":"code","source":"# Utility function to create folders and callbacks for training\nfrom datetime import datetime\n\n\ndef create_folders_and_callbacks(model_name):\n    exps_dir = os.path.join('experiments')\n    if not os.path.exists(exps_dir):\n        os.makedirs(exps_dir)\n\n    now = datetime.now().strftime('%b%d_%H-%M-%S')\n\n    exp_dir = os.path.join(exps_dir, model_name + '_' + str(now))\n    if not os.path.exists(exp_dir):\n        os.makedirs(exp_dir)\n\n    callbacks = [\n        tfk.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=10, restore_best_weights=True),\n        tfk.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', patience=5, factor=0.5, min_lr=1e-5)\n    ]\n\n    # Model checkpoint\n    # ----------------\n    ckpt_dir = os.path.join(exp_dir, 'ckpts')\n    if not os.path.exists(ckpt_dir):\n        os.makedirs(ckpt_dir)\n\n    ckpt_callback = tf.keras.callbacks.ModelCheckpoint(\n        filepath=os.path.join(ckpt_dir, 'cp'),\n        save_weights_only=False,\n        save_best_only=False)\n    callbacks.append(ckpt_callback)\n\n    # Visualize Learning on Tensorboard\n    # ---------------------------------\n    tb_dir = os.path.join(exp_dir, 'tb_logs')\n    if not os.path.exists(tb_dir):\n        os.makedirs(tb_dir)\n\n    tb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_dir,\n                                                 profile_batch=0,\n                                                 histogram_freq=1)\n    callbacks.append(tb_callback)\n\n    return callbacks","metadata":{"id":"0hA4yjjK1M6s"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Exploration Data Analysis (EDA)\n","metadata":{"id":"S9TBGTJFtaI1"}},{"cell_type":"code","source":"dataset = pd.read_csv('/kaggle/input/training/Training.csv')\nprint(dataset.shape)\ndataset.head()","metadata":{"id":"YB1vxLkYyfFQ","outputId":"621ab64a-370a-4380-f46b-107d1036b3a4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.info()","metadata":{"id":"f75FMAA1CNA2","outputId":"d9823a87-7434-4ab7-de3f-49cfc5e45420"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def inspect_dataframe(df, columns):\n    figs, axs = plt.subplots(len(columns), 1, sharex=True, figsize=(17, 17))\n    for i, col in enumerate(columns):\n        axs[i].plot(df[col])\n        axs[i].set_title(col)\n    plt.show()\n\n\ninspect_dataframe(dataset, dataset.columns)","metadata":{"id":"HXpSLGgC902P","outputId":"5c054206-30f3-4f0f-d64f-1addd3c0f438"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Normalization","metadata":{"id":"pUqW6PgmNsem"}},{"cell_type":"code","source":"# Data normalization\n\nX_train_raw = dataset\nX_min = X_train_raw.min()\nX_max = X_train_raw.max()\nX_train_raw = (X_train_raw - X_min) / (X_max - X_min)\n\nprint(X_train_raw.shape)\nprint(dataset)\n\n# Plot dataset after normalization\ninspect_dataframe(X_train_raw, X_train_raw.columns)","metadata":{"id":"wB4jRVsPJw25","outputId":"2c45314d-7fce-46a8-e225-64bdef599838"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"window = 1600\nstride = 100","metadata":{"id":"5U5QeKoWJP9X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"future = dataset[-window:]\nfuture = (future - X_min) / (X_max - X_min)\nfuture = np.expand_dims(future, axis=0)\nfuture.shape","metadata":{"id":"n0ckE6LaO68r","outputId":"28681caa-f3e4-4b05-9e1a-0afb60f17667"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_sequences(df, p_target_labels=dataset.columns, p_window=1600, p_stride=100, p_telescope=864):\n    # Sanity check to avoid runtime errors\n    assert p_window % p_stride == 0\n    ds = []\n    labels = []\n    temp_df = df.copy().values\n    temp_label = df[p_target_labels].copy().values\n    padding_len = len(df) % p_window\n\n    if padding_len != 0:\n        # Compute padding length\n        padding_len = p_window - len(df) % p_window\n        padding = np.zeros((padding_len, temp_df.shape[1]), dtype='float32')  # Change to float32\n        temp_df = np.concatenate((padding, df))\n        padding = np.zeros((padding_len, temp_label.shape[1]), dtype='float32')\n        temp_label = np.concatenate((padding, temp_label))\n        assert len(temp_df) % p_window == 0\n\n    for idx in np.arange(0, len(temp_df) - p_window - p_telescope, p_stride):\n        ds.append(temp_df[idx:idx + p_window])\n        labels.append(temp_label[idx + p_window:idx + p_window + p_telescope])\n\n    ds = np.array(ds)\n    labels = np.array(labels)\n    return ds, labels","metadata":{"id":"SFoJa5kMkq2g"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Multivariate Forecasting (Direct)","metadata":{"id":"LgY5g6xUDswZ"}},{"cell_type":"code","source":"target_labels = dataset.columns\ntelescope = 864","metadata":{"id":"jU3_acq542V-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, y_train = build_sequences(X_train_raw, target_labels, window, stride, telescope)\nX_train.shape, y_train.shape","metadata":{"id":"e_dsZ1Mb41DH","outputId":"c53ad9de-da5b-4ad8-91d4-5bd1652beda1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def inspect_multivariate(X, y, columns, p_telescope, idx=None):\n    if idx is None:\n        idx = np.random.randint(0, len(X))\n\n    figs, axs = plt.subplots(len(columns), 1, sharex=True, figsize=(17, 17))\n    for i, col in enumerate(columns):\n        axs[i].plot(np.arange(len(X[0, :, i])), X[idx, :, i])\n        axs[i].scatter(np.arange(len(X[0, :, i]), len(X_train[0, :, i]) + p_telescope), y[idx, :, i], color='orange')\n        axs[i].set_title(col)\n        axs[i].set_ylim(0, 1)\n    plt.show()","metadata":{"id":"ruqsimHHmqzJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inspect_multivariate(X_train, y_train, target_labels, telescope)","metadata":{"id":"jKVNgYSmDxp4","outputId":"a9d7600b-b143-4436-9d9c-e011ff0c3278"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_shape = X_train.shape[1:]\noutput_shape = y_train.shape[1:]\nbatch_size = 64\nepochs = 200\n\n# Source: https://arxiv.org/abs/1711.00489\n# Is it a good tradeoff? Memory vs just decreasing a value","metadata":{"id":"AASFwzzCCGNn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_stacked_LSTM_model(p_input_shape, p_output_shape):\n\n    input_layer = tfkl.Input(shape=p_input_shape, name='Input')\n\n    lstm1 = tfkl.LSTM(64, activation='relu', return_sequences=True, input_shape=(p_input_shape))(input_layer)\n    lstm2 = tfkl.LSTM(64, activation='relu')(lstm1)\n    dense1 = tfkl.Dense(128)(lstm2)\n    dropout = tfkl.Dropout(.3)(dense1)\n    dense2 = tfkl.Dense(p_output_shape[-1]*p_output_shape[-2], activation='relu')(dropout)\n    output_layer = tfkl.Reshape((p_output_shape[-2],p_output_shape[-1]))(dense2)\n    output_layer = tfkl.Conv1D(p_output_shape[-1], 1, padding='same')(output_layer)\n\n  # Connect input and output through the Model class\n  model = tfk.Model(inputs=input_layer, outputs=output_layer, name='model')\n\n  # Compile the model\n  model.compile(loss=tfk.losses.MeanSquaredError(), optimizer=tfk.optimizers.Adam(), metrics=[tf.keras.metrics.RootMeanSquaredError()])\n\n  # Return the model\n  return model","metadata":{"id":"jP_H1wc_CGK5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = build_stacked_LSTM_model(input_shape, output_shape)\nmodel.summary()\ntfk.utils.plot_model(model, expand_nested=True)","metadata":{"id":"MhAmgJKZCGIl","outputId":"d043d317-d714-4040-d3ff-daec4d185bd1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the model\ncallbacks = create_folders_and_callbacks(model_name='StackedLSTM')\n\nhistory = model.fit(\n    x=X_train,\n    y=y_train,\n    batch_size=batch_size,\n    epochs=epochs,\n    validation_split=.1,\n    callbacks=callbacks\n).history","metadata":{"id":"5eIM0f0SCGF3","outputId":"223f2079-a91d-41a5-d48f-e488626a19be"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('StackedLSTM')","metadata":{"id":"eZFKysQLrMSF","outputId":"3997833d-c2ca-4674-d8f7-b32058dc479b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_epoch = np.argmin(history['val_loss'])\nplt.figure(figsize=(17, 4))\nplt.plot(history['loss'], label='Training loss', alpha=.8, color='#ff7f0e')\nplt.plot(history['val_loss'], label='Validation loss', alpha=.9, color='#5a9aa5')\nplt.axvline(x=best_epoch, label='Best epoch', alpha=.3, ls='--', color='#5a9aa5')\nplt.title('Mean Squared Error (Loss)')\nplt.legend()\nplt.grid(alpha=.3)\nplt.show()\n\nplt.figure(figsize=(17, 4))\nplt.plot(history['root_mean_squared_error'], label='Training RMSE', alpha=.8, color='#ff7f0e')\nplt.plot(history['val_root_mean_squared_error'], label='Validation RMSE', alpha=.9, color='#5a9aa5')\nplt.axvline(x=best_epoch, label='Best epoch', alpha=.3, ls='--', color='#5a9aa5')\nplt.title('RMSE')\nplt.legend()\nplt.grid(alpha=.3)\nplt.show()\n\nplt.figure(figsize=(18, 3))\nplt.plot(history['lr'], label='Learning Rate', alpha=.8, color='#ff7f0e')\nplt.axvline(x=best_epoch, label='Best epoch', alpha=.3, ls='--', color='#5a9aa5')\nplt.legend()\nplt.grid(alpha=.3)\nplt.show()","metadata":{"id":"GLUlKfK0CGDg","outputId":"3a892f40-7287-465c-93a0-54d9382137ff"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"qq1dSlucCT72"},"execution_count":null,"outputs":[]}]}